{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import jellyfish\n",
    "import openai\n",
    "from operator import itemgetter\n",
    "from typing import Optional, Union, Dict, Any, List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import BasePromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnablePassthrough, RunnableLambda\n",
    "\n",
    "import clickhouse_connect\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for Extracting Valid Values from the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_as_list(db, query):\n",
    "    \"\"\" Execute a SQL query and return a list of cleaned unique elements. \"\"\"\n",
    "    res = db.run(query)\n",
    "    res = [el[0] for el in res if el and el[0]]  # Extract first element from tuple\n",
    "    res = [re.sub(r\"\\b\\d+\\b\", \"\", string).strip() for string in res]  # Remove numeric values\n",
    "    return list(set(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_values(db):\n",
    "    \"\"\"Extract valid values for brand, l1_category, and l3_category from the database.\"\"\"\n",
    "    valid_brand = []\n",
    "    valid_brand += query_as_list(db, \"SELECT DISTINCT brand FROM product_view\")\n",
    "    valid_brand += query_as_list(db, \"SELECT DISTINCT brand FROM product_wishlist_add\")\n",
    "    valid_brand += query_as_list(db, \"SELECT DISTINCT brand FROM product_wishlist_remove\")\n",
    "    valid_brand += query_as_list(db, \"SELECT DISTINCT brand FROM add_to_cart\")\n",
    "    valid_brand += query_as_list(db, \"SELECT DISTINCT brand FROM remove_from_cart\")\n",
    "    valid_brand = list(set(valid_brand))\n",
    "    \n",
    "    valid_l1 = query_as_list(db, \"SELECT DISTINCT l1_category FROM product_view\")\n",
    "    valid_l1 = list(set(valid_l1))\n",
    "    \n",
    "    valid_l3 = []\n",
    "    valid_l3 += query_as_list(db, \"SELECT DISTINCT l3_category FROM product_view\")\n",
    "    valid_l3 += query_as_list(db, \"SELECT DISTINCT l3_category FROM product_wishlist_add\")\n",
    "    valid_l3 += query_as_list(db, \"SELECT DISTINCT l3_category FROM product_wishlist_remove\")\n",
    "    valid_l3 += query_as_list(db, \"SELECT DISTINCT l3_category FROM add_to_cart\")\n",
    "    valid_l3 += query_as_list(db, \"SELECT DISTINCT l3_category FROM remove_from_cart\")\n",
    "    valid_l3 = list(set(valid_l3))\n",
    "    \n",
    "    return {\n",
    "        \"brand\": valid_brand,\n",
    "        \"l1_category\": valid_l1,\n",
    "        \"l3_category\": valid_l3,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzy Category Mapping and Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_correction(candidate, valid_values, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Returns a tuple (best_match, best_score) for the candidate compared to a list of valid values.\n",
    "    \"\"\"\n",
    "    best_match = candidate\n",
    "    best_score = 0\n",
    "    for val in valid_values:\n",
    "        score = jellyfish.jaro_winkler_similarity(candidate.lower(), val.lower())\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = val\n",
    "    return best_match, best_score\n",
    "\n",
    "def process_l1_l3_candidates(extracted_l1, extracted_l3, valid_l1, valid_l3, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Processes ambiguous candidates for l1 and l3.\n",
    "    If one list is empty, duplicate its candidate(s) from the other.\n",
    "    For each candidate in the union, compute its best correction against both valid lists\n",
    "    and choose the correction with the higher similarity score.\n",
    "    Returns a mapping: candidate -> {\"value\": final_correction, \"column\": \"L1_category\" or \"L3_category\", \"score\": <score>}.\n",
    "    \"\"\"\n",
    "    if not extracted_l1 and extracted_l3:\n",
    "        extracted_l1 = extracted_l3.copy()\n",
    "    if not extracted_l3 and extracted_l1:\n",
    "        extracted_l3 = extracted_l1.copy()\n",
    "\n",
    "    final_corrections = {}\n",
    "    all_candidates = set(extracted_l1).union(set(extracted_l3))\n",
    "    for candidate in all_candidates:\n",
    "        corr_l1, score_l1 = get_best_correction(candidate, valid_l1, threshold)\n",
    "        corr_l3, score_l3 = get_best_correction(candidate, valid_l3, threshold)\n",
    "        if score_l1 >= score_l3:\n",
    "            final_corrections[candidate] = {\"value\": corr_l1, \"column\": \"L1_category\", \"score\": score_l1}\n",
    "        else:\n",
    "            final_corrections[candidate] = {\"value\": corr_l3, \"column\": \"L3_category\", \"score\": score_l3}\n",
    "    return final_corrections\n",
    "\n",
    "def process_extracted_categories(extracted_dict, combined_valid_values, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Processes extracted category values.\n",
    "    For 'brand', uses normal fuzzy matching.\n",
    "    For ambiguous l1_category and l3_category values, returns a mapping (candidate -> correction mapping).\n",
    "    The result is a dictionary with keys \"brand\" and \"l1_l3\".\n",
    "    \"\"\"\n",
    "    corrected = {}\n",
    "    # Process brand normally.\n",
    "    if \"brand\" in extracted_dict:\n",
    "        corrected_brand = []\n",
    "        for val in extracted_dict[\"brand\"]:\n",
    "            corr, _ = get_best_correction(val, combined_valid_values.get(\"brand\", []), threshold)\n",
    "            corrected_brand.append(corr)\n",
    "        corrected[\"brand\"] = corrected_brand\n",
    "\n",
    "    # Process ambiguous l1 and l3 candidates.\n",
    "    extracted_l1 = extracted_dict.get(\"l1_category\", [])\n",
    "    extracted_l3 = extracted_dict.get(\"l3_category\", [])\n",
    "    if not extracted_l1 and extracted_l3:\n",
    "        extracted_l1 = extracted_l3.copy()\n",
    "    if not extracted_l3 and extracted_l1:\n",
    "        extracted_l3 = extracted_l1.copy()\n",
    "\n",
    "    valid_l1 = combined_valid_values.get(\"l1_category\", [])\n",
    "    valid_l3 = combined_valid_values.get(\"l3_category\", [])\n",
    "    \n",
    "    l1l3_mapping = process_l1_l3_candidates(extracted_l1, extracted_l3, valid_l1, valid_l3, threshold)\n",
    "    corrected[\"l1_l3\"] = l1l3_mapping\n",
    "    return corrected\n",
    "\n",
    "def fuzzy_prompt_replace(prompt, extracted_value, corrected_value, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Searches the prompt for an n-gram (n = number of words in extracted_value)\n",
    "    that is similar to extracted_value using Jaro‚ÄìWinkler similarity.\n",
    "    If a match above threshold is found, replaces that substring with corrected_value.\n",
    "    \"\"\"\n",
    "    tokens = prompt.split()\n",
    "    n = len(extracted_value.split())\n",
    "    best_index = None\n",
    "    best_score = 0\n",
    "    best_substring = None\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        candidate = \" \".join(tokens[i:i+n])\n",
    "        score = jellyfish.jaro_winkler_similarity(candidate.lower(), extracted_value.lower())\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_index = i\n",
    "            best_substring = candidate\n",
    "    if best_score >= threshold and best_substring:\n",
    "        new_tokens = tokens[:best_index] + [corrected_value] + tokens[best_index+n:]\n",
    "        return \" \".join(new_tokens)\n",
    "    else:\n",
    "        return prompt\n",
    "\n",
    "def extract_categories_from_prompt(prompt):\n",
    "    \"\"\"\n",
    "    Uses LangChain's ChatOpenAI to extract categorical values (brand, l1_category, l3_category)\n",
    "    from the user prompt. The output is expected to be a JSON dictionary.\n",
    "    \"\"\"\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant that extracts categorical values from user prompts. \"\n",
    "        \"Given a prompt, output a JSON object with keys 'brand', 'l1_category', and 'l3_category'. \"\n",
    "        \"Each key should map to a list of values found in the prompt. If a category is not mentioned, \"\n",
    "        \"output an empty list for that key. For example, if the prompt is: \"\n",
    "        \"'get all the users who wishlied shirts from catawalk brand products and added to cart but did not checkout', \"\n",
    "        \"then you should output: {\\\"brand\\\": [\\\"Catwalk\\\"], \\\"l1_category\\\": [\\\"Shirts\\\"], \\\"l3_category\\\": []}. \"\n",
    "        \"Output only a valid JSON object with no extra text. \"\n",
    "        \"make sure ```json  ``` does not come in the response \"\n",
    "    )\n",
    "    user_message = f\"Extract categories from the following prompt in JSON format:\\n\\n{prompt}\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    response = llm.invoke(f\"{system_message}\\n\\n{user_message}\")\n",
    "    try:\n",
    "        extracted = response.content.strip()\n",
    "        extracted_dict = json.loads(extracted)\n",
    "    except Exception as e:\n",
    "        print(\"Error extracting categories from prompt:\", e)\n",
    "        print(\"Raw response:\", response.content if hasattr(response, \"content\") else response)\n",
    "        extracted_dict = {}\n",
    "    return extracted_dict\n",
    "\n",
    "def correct_prompt(original_prompt, extracted_dict, corrected_mapping, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Updates the original prompt using fuzzy replacement.\n",
    "    For 'brand' and for each candidate in the ambiguous l1/l3 mapping,\n",
    "    finds the best matching n-gram in the prompt and replaces it with the final corrected value,\n",
    "    appending the column name in parentheses.\n",
    "    \"\"\"\n",
    "    corrected_prompt = original_prompt\n",
    "    # Process brand replacement.\n",
    "    for orig, corr in zip(extracted_dict.get(\"brand\", []), corrected_mapping.get(\"brand\", [])):\n",
    "        replacement = f\"{corr} (brand)\"\n",
    "        corrected_prompt = fuzzy_prompt_replace(corrected_prompt, orig, replacement, threshold)\n",
    "    # Process ambiguous l1/l3 candidates.\n",
    "    for candidate, mapping in corrected_mapping.get(\"l1_l3\", {}).items():\n",
    "        replacement = f\"{mapping['value']} ({mapping['column']})\"\n",
    "        corrected_prompt = fuzzy_prompt_replace(corrected_prompt, candidate, replacement, threshold)\n",
    "    return corrected_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clickhouse COnnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClickHouseSQLDatabase:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize ClickHouse connection.\"\"\"\n",
    "        self.host = os.getenv(\"host\")\n",
    "        self.port = int(os.getenv(\"port\", 8123))  # Default ClickHouse HTTP port\n",
    "        self.user = os.getenv(\"user\", \"default\")\n",
    "        self.password = os.getenv(\"password\", \"\")\n",
    "        self.database = os.getenv(\"database\", \"default\")\n",
    "        os.environ['OPENAI_API_KEY'] = os.getenv(\"OPEN_AI_API_KEY\")\n",
    "\n",
    "        # Create ClickHouse client\n",
    "        self.client = clickhouse_connect.get_client(\n",
    "            host=self.host, port=self.port, username=self.user, password=self.password, database=self.database\n",
    "        )\n",
    "\n",
    "        # Load LLM for query correction\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o\", temperature=0, top_p=0.1)\n",
    "\n",
    "    def get_usable_table_names(self):\n",
    "        \"\"\"Fetches the list of tables in the ClickHouse database.\"\"\"\n",
    "        result = self.client.query(\"SHOW TABLES\")\n",
    "        return [row[0] for row in result.result_set]\n",
    "\n",
    "    def get_table_info(self, table_names=None):\n",
    "        \"\"\"\n",
    "        Fetches schema details for the specified tables.\n",
    "        If no table_names are provided, fetches schema for all tables.\n",
    "        \"\"\"\n",
    "        if table_names is None:\n",
    "            table_names = self.get_usable_table_names()\n",
    "\n",
    "        table_info = \"\"\n",
    "        for table in table_names:\n",
    "            query = f\"\"\"\n",
    "            SELECT name, type \n",
    "            FROM system.columns \n",
    "            WHERE database = '{self.database}' AND table = '{table}'\n",
    "            \"\"\"\n",
    "            result = self.client.query(query)\n",
    "            columns = [f\"{row[0]} ({row[1]})\" for row in result.result_set]\n",
    "            table_info += f\"Table: {table}\\nColumns: {', '.join(columns)}\\n\\n\"\n",
    "\n",
    "        return table_info.strip()\n",
    "\n",
    "    def run(self, query: str, retries: int = 3, fetch=\"all\", include_columns=False):\n",
    "        \"\"\"\n",
    "        Executes a SQL query with up to 3 retries using LLM for query correction.\n",
    "\n",
    "        Args:\n",
    "            query (str): The SQL query to execute.\n",
    "            retries (int): Number of retries allowed for query correction.\n",
    "            fetch (str): \"all\" for all rows, \"one\" for a single row, \"many\" for first 10 rows.\n",
    "            include_columns (bool): If True, return result as list of dicts with column names.\n",
    "\n",
    "        Returns:\n",
    "            list | str: Query results or error message.\n",
    "        \"\"\"\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                # Execute SQL query\n",
    "                result = self.client.query(query)\n",
    "\n",
    "                # Format the output\n",
    "                if fetch == \"one\":\n",
    "                    output = result.result_set[0] if result.result_set else None\n",
    "                elif fetch == \"many\":\n",
    "                    output = result.result_set[:10]\n",
    "                else:\n",
    "                    output = result.result_set  # Default: all rows\n",
    "\n",
    "                # Include column names if required\n",
    "                if include_columns:\n",
    "                    columns = [col[0] for col in result.columns]\n",
    "                    output = [dict(zip(columns, row)) for row in output]\n",
    "\n",
    "                return output  # ‚úÖ Successfully executed\n",
    "\n",
    "            except Exception as e:\n",
    "                error_message = str(e)\n",
    "                print(f\"‚ö†Ô∏è Query failed on attempt {attempt + 1}: {error_message}\")\n",
    "\n",
    "                if attempt < retries - 1:\n",
    "                    # Regenerate query with LLM using the same system prompt\n",
    "                    query = self.regenerate_query_with_llm(query, error_message)\n",
    "                    print(f\"üîÑ Retrying with corrected query:\\n{query}\\n\")\n",
    "                    time.sleep(1)  # Small delay before retrying\n",
    "                else:\n",
    "                    print(\"‚ùå Max retries reached. Returning error message.\")\n",
    "                    return f\"Query failed after {retries} attempts: {error_message}\"\n",
    "\n",
    "    def regenerate_query_with_llm(self, query, error_message):\n",
    "        \"\"\"\n",
    "        Uses the same system prompt to correct SQL queries based on errors.\n",
    "        Now instructs the LLM to respect column data types when generating comparisons.\n",
    "\n",
    "        Note: Ensure that string columns are enclosed in quotes while numeric columns are not.\n",
    "        \"\"\"\n",
    "        system_prompt = f\"\"\"\n",
    "        You are a SQL expert. Given an input question or an incorrect SQL query, generate a syntactically \n",
    "        correct SQL query that runs successfully on ClickHouse. \n",
    "\n",
    "        **Instructions:**\n",
    "        - If an error message is provided, analyze it and correct the query accordingly.\n",
    "        - You will just return the **Clickhouse executable** SQL query and make sure not to add any markdown formatting.\n",
    "        - Do NOT remove or alter the filter: application_id = '{os.getenv(\"application_id\")}'.\n",
    "        - Ensure all table and column names exist in the provided schema.\n",
    "        - When filtering or comparing values, pay close attention to the column data types:\n",
    "            - Enclose values in single quotes if the column type is a string.\n",
    "            - Do not use quotes if the column type is numeric.\n",
    "        - If filtering or comparing values from an array column, use `arraySum()` or `arrayJoin()`.\n",
    "        - Do not return explanations; only return the corrected SQL query.\n",
    "\n",
    "        **Database Schema:**\n",
    "        {self.get_table_info()}\n",
    "\n",
    "        **Error Message:**\n",
    "        {error_message}\n",
    "\n",
    "        **Incorrect Query:**\n",
    "        {query}\n",
    "\n",
    "        Now, generate a correct SQL query.\n",
    "        \"\"\"\n",
    "\n",
    "        corrected_query = self.llm.invoke(system_prompt)\n",
    "        return corrected_query.content.strip() # ‚úÖ Returns corrected SQL query\n",
    "\n",
    "    @property\n",
    "    def dialect(self):\n",
    "        \"\"\"Returns a string representing the database dialect.\"\"\"\n",
    "        return \"clickhouse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate CLickhouse instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ClickHouseSQLDatabase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the names of the brands, L1 and L3 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_valid_values = get_valid_values(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1731 unique proper nouns\n"
     ]
    }
   ],
   "source": [
    "# Extract proper nouns from relevant tables\n",
    "proper_nouns = []\n",
    "proper_nouns += query_as_list(db, \"SELECT DISTINCT brand FROM product_view\")\n",
    "proper_nouns += query_as_list(db, \"SELECT DISTINCT l1_category FROM product_view\")\n",
    "proper_nouns += query_as_list(db, \"SELECT DISTINCT l3_category FROM product_view\")\n",
    "proper_nouns += query_as_list(db, \"SELECT DISTINCT brand FROM product_wishlist_add\")\n",
    "proper_nouns += query_as_list(db, \"SELECT DISTINCT l3_category FROM product_wishlist_add\")\n",
    "proper_nouns += query_as_list(db, \"SELECT DISTINCT brand FROM product_wishlist_remove\")\n",
    "proper_nouns += query_as_list(db, \"SELECT DISTINCT l3_category FROM product_wishlist_remove\")\n",
    "proper_nouns += query_as_list(db, \"SELECT DISTINCT brand FROM add_to_cart\")\n",
    "proper_nouns += query_as_list(db, \"SELECT DISTINCT l3_category FROM add_to_cart\")\n",
    "proper_nouns += query_as_list(db, \"SELECT DISTINCT brand FROM remove_from_cart\")\n",
    "proper_nouns += query_as_list(db, \"SELECT DISTINCT l3_category FROM remove_from_cart\")\n",
    "\n",
    "proper_nouns = list(set(proper_nouns))\n",
    "print(f\"Extracted {len(proper_nouns)} unique proper nouns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_agent_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "def correct_query_using_llm(query, proper_nouns):\n",
    "    \"\"\"\n",
    "    Uses an LLM to correct misspelled words in a query based on known database terms.\n",
    "    \"\"\"\n",
    "    system_prompt = f\"\"\"\n",
    "    You are an expert in natural language correction for SQL queries. Your job is to correct any misspelled words \n",
    "    in the given question while preserving its original meaning. \n",
    "\n",
    "    - Only correct words if they appear to be misspellings of a known brand, product, or category.\n",
    "    - Do NOT change common words like \"how,\" \"many,\" \"added,\" \"to,\" etc.\n",
    "    - Ensure that the corrected query is as close as possible to the original.\n",
    "    - Use the provided list of valid words to make corrections.\n",
    "\n",
    "    List of valid brand names and categories: {proper_nouns}\n",
    "    \"\"\"\n",
    "\n",
    "    corrected_query = sql_agent_llm.invoke(f\"{system_prompt}\\n\\nQuery: {query}\\nCorrected Query:\")\n",
    "    return corrected_query.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enforcing Application ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enforce_application_id_filter(sql_query: str, application_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Ensures that the SQL query includes a filter for `application_id`.\n",
    "    \"\"\"\n",
    "    application_filter = f\"application_id = '{application_id}'\"\n",
    "\n",
    "    # Check if WHERE clause exists\n",
    "    if re.search(r\"\\bWHERE\\b\", sql_query, re.IGNORECASE):\n",
    "        # Append to existing WHERE clause\n",
    "        sql_query = re.sub(r\"(\\bWHERE\\b)\", r\"\\1 \" + application_filter + \" AND\", sql_query, flags=re.IGNORECASE)\n",
    "    else:\n",
    "        # Add new WHERE clause\n",
    "        sql_query = re.sub(r\"(\\bFROM\\b\\s+\\w+)\", r\"\\1 WHERE \" + application_filter, sql_query, flags=re.IGNORECASE)\n",
    "\n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the SQL Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sql_query_chain(\n",
    "    llm: ChatOpenAI,\n",
    "    db: ClickHouseSQLDatabase,\n",
    "    prompt: Optional[BasePromptTemplate] = None,\n",
    "    k: int = 5,\n",
    ") -> Runnable:\n",
    "    \"\"\"\n",
    "    Creates a LangChain runnable that generates SQL queries, enforces application_id filtering,\n",
    "    and applies retries for errors.\n",
    "    \"\"\"\n",
    "    if prompt is None:\n",
    "        raise ValueError(\"A valid SQL generation prompt must be provided.\")\n",
    "\n",
    "    application_id = os.getenv(\"application_id\")\n",
    "    if not application_id:\n",
    "        raise ValueError(\"Missing application_id. Ensure it is set in the environment variables.\")\n",
    "\n",
    "    inputs = {\n",
    "        \"input\": lambda x: x[\"question\"] + \"\\nSQLQuery: \",\n",
    "        \"table_info\": lambda x: db.get_table_info(table_names=x.get(\"table_names_to_use\")),\n",
    "        \"application_id\": lambda _: application_id,\n",
    "    }\n",
    "\n",
    "    return (\n",
    "        RunnablePassthrough.assign(**inputs)\n",
    "        | prompt.partial(top_k=str(k))\n",
    "        | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "        | StrOutputParser()\n",
    "        | (lambda query: enforce_application_id_filter(query, application_id))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a SQL expert. Given an input question, create a syntactically \\\n",
    "correct CLICKHOUSE executable SQL query to run. Unless otherwise specified, do not return more than \\\n",
    "{top_k} rows.\n",
    "\n",
    "While making the query take into consideration the proper query given by = {corrected_query}\n",
    "\n",
    "You can join relevant tables to get the best query possible.\n",
    "Here is the relevant table info: {table_info}\n",
    "\n",
    "Ensure that every query includes the filter `application_id = '{application_id}'`.\n",
    "\n",
    "Follow the below instructions:\n",
    "\n",
    "1) You will just return the SQL query and make sure not to add ```sql before or after the query.\n",
    "2) Make sure to generate a **Clickhouse executable** SQL query\n",
    "3) If filtering or comparing values from an array column, use `arraySum()` or `arrayJoin()`.\n",
    "4) When comparing or filtering values, use the column type information from the schema:\n",
    "   - Enclose string values in single quotes.\n",
    "   - Do not enclose numeric values in quotes.\n",
    "5) In the user prompt you are given which column to consider in the brackets of each values, for example Loungewear (L3_category) from Raymond (brand).\n",
    "6) For checking if a value exists in an array, use `has(array, value)` instead of `ANY()`\n",
    "7) For applying filters or checking values convert everything into lowercase, for example lower(brand) = lower(Gucci)\n",
    "8) please dont use any tables anme staring with \".inner_id.\"in the query. \n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system_prompt), (\"human\", \"{input}\")])\n",
    "\n",
    "query_chain = create_sql_query_chain(sql_agent_llm, db, prompt=prompt, k=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Full Correction Function (Integrating Category Mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_correction(query):\n",
    "    # Step 1: Correct misspellings using the original LLM-based method.\n",
    "    corrected_query = correct_query_using_llm(query, proper_nouns)\n",
    "    \n",
    "    # Step 2: Extract categories from the corrected query.\n",
    "    extracted = extract_categories_from_prompt(corrected_query)\n",
    "    if not extracted.get(\"l1_category\") and extracted.get(\"l3_category\"):\n",
    "        extracted[\"l1_category\"] = extracted[\"l3_category\"].copy()\n",
    "    if not extracted.get(\"l3_category\") and extracted.get(\"l1_category\"):\n",
    "        extracted[\"l3_category\"] = extracted[\"l1_category\"].copy()\n",
    "    \n",
    "    # Step 3: Process the extracted categories using the valid values from the DB.\n",
    "    mapping = process_extracted_categories(extracted, combined_valid_values, threshold=0.85)\n",
    "    \n",
    "    # Step 4: Use fuzzy replacement to correct the prompt with proper category mapping.\n",
    "    final_query = correct_prompt(corrected_query, extracted, mapping, threshold=0.8)\n",
    "    return final_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_chain = (\n",
    "    RunnableLambda(lambda input: input[\"question\"])  # Extract the original question.\n",
    "    | RunnableLambda(lambda query: full_correction(query))  # Full correction: spelling + category mapping.\n",
    "    | RunnableLambda(lambda corrected: {\"question\": corrected, \"corrected_query\": corrected})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnablePassthrough.assign(\n",
    "    corrected_query=correction_chain,\n",
    "    table_info=lambda input: db.get_table_info()\n",
    ") | query_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"i want to see the top 100 users who spent more than 2000 on tshirts, chinas, loungewaer, casaual sherts , footwer , clothing together\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_query = correction_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'I want to see the top 100 users who spent more than 2000 on T-Shirts (L3_category) Chinos (L3_category) Loungewear (L3_category) Casual Shirts (L3_category) Footwear (L1_category) Clothing (L1_category) together.', 'corrected_query': 'I want to see the top 100 users who spent more than 2000 on T-Shirts (L3_category) Chinos (L3_category) Loungewear (L3_category) Casual Shirts (L3_category) Footwear (L1_category) Clothing (L1_category) together.'}\n"
     ]
    }
   ],
   "source": [
    "print(corrected_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT \n",
      "    user_id, \n",
      "    SUM(price * quantity) AS total_spent\n",
      "FROM \n",
      "    add_to_cart\n",
      "WHERE application_id = '000000000000000000000001' AND \n",
      "    lower(l3_category) IN ('t-shirts', 'chinos', 'loungewear', 'casual shirts') \n",
      "    OR lower(l1_category) IN ('footwear', 'clothing')\n",
      "    AND application_id = '000000000000000000000001'\n",
      "GROUP BY \n",
      "    user_id\n",
      "HAVING \n",
      "    total_spent > 2000\n",
      "ORDER BY \n",
      "    total_spent DESC\n",
      "LIMIT 100;\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\"question\": question})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 111634.0),\n",
       " ('679f96e219b98690a755e180', 5975.0),\n",
       " ('67cc12f427c572dbdc6a33c7', 2898.0),\n",
       " ('67ab38d1c9329259c2438419', 2249.0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"i want to see the top 100 users who spent more than 2000 in the last 7 days.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT user_id, SUM(order_value) AS total_spent\n",
      "FROM sales_summary\n",
      "WHERE application_id = '000000000000000000000001' AND order_created_at >= now() - INTERVAL 7 DAY\n",
      "AND total_order_value > 2000\n",
      "AND application_id = '000000000000000000000001'\n",
      "GROUP BY user_id\n",
      "ORDER BY total_spent DESC\n",
      "LIMIT 100;\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\"question\": question})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zenith_express",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
